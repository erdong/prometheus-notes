
# Prometheus Kafka Adapter

在使用 Prometheus 的时候，有时候我们需要把 Prometheus 的数据导出到其他系统里，这样可以有另外的处理方式。

我们可以通过远程写的方式，将 Prometheus 的数据实时的写到其他系统。Prometheus 支持很多远程写的系统，详细的可以查看 Prometheus 的 [Remote Endpoints and Storage](https://prometheus.io/docs/operating/integrations/#remote-endpoints-and-storage) ，现在我们来看看 Prometheus 怎么写入到 Kafka 系统。

Prometheus 官方推荐了一个中间件，用来连接 Prometheus 和 Kafka ，这个组件就是 `prometheus-kafka-adapter` ，这个组件的官方地址是  https://github.com/telefonica/prometheus-kafka-adapter 。这个组件最后的更新时间是 2020 年 6 月 4 日，版本是 v1.7.0 ，到现在已经一年多没有更新了。但是没有其他推荐的组件，并且经过测试，当前可以版本还可以继续使用，我们使用 Prometheus 版本是 v2.29.1 。使用这个组件需要 Prometheus 将数据实时的推送到 `prometheus-kafka-adapter` ，然后 `prometheus-kafka-adapter` 将数据推送到 Kafka。



# 启动 adapter

`prometheus-kafka-adapter` 提供了构建好的 Docker 镜像，存储在 Docker Hub 上，我们将镜像拉取下来以后可以使用如下的 shell 脚本来启动这个镜像。

在启动 `prometheus-kafka-adapter` 之前我们需要先搭建好 Kafka 并且创建好 Kafka 的 Topic ，这个在 Kafka 的使用中是基础操作，我们就不再描述，大家可以自行搜索学习，也可以让公司的 Kafka  管理员来提供对应的信息。

我们需要先准备好 Kafka 的地址和监听端口，以及专门用来中转数据的 Topic ，我们这次的 Topic 名称是 `prometheus-metric` .

```
#!/usr/bin/env bash

docker run -d --name prometheus-kafka-adapter-01 --restart=always -m 2g \
-e KAFKA_BROKER_LIST=192.168.50.90:9093 \
-e KAFKA_TOPIC=prometheus-metric \
-e PORT=10401 \
-e SERIALIZATION_FORMAT=json \
-e GIN_MODE=release \
-e LOG_LEVEL=debug \
-p 10401:10401 \
telefonica/prometheus-kafka-adapter:1.7.0 \
```


上边的脚本除了启动一个容器以外，还做了一些容器的加固。另外配置 `prometheus-kafka-adapter` 的监听端口 10401 ，只要 Prometheus 向这个端口推送数据，adapter 就能收到。

当前这个 Kafka 是没有认证的要求的，如果 Kafka 启用了秘钥或者口令的验证方式的话，也可以通过配置环境变量选择相应的参数来进行配置。

## 基于 SSL 的秘钥认证参数

* KAFKA_SSL_CLIENT_CERT_FILE: Kafka SSL client 认证文件
* KAFKA_SSL_CLIENT_KEY_FILE: Kafka SSL client 认证秘钥文件
* KAFKA_SSL_CLIENT_KEY_PASS: Kafka SSL client 认证秘钥文件的密码，是一个可选项
* KAFKA_SSL_CA_CERT_FILE: Kafka SSL  的 CA 认证文件
  
这些选项的默认值都是 `""`

## 基于 SASL/SCRAM  的口令认证参数

* KAFKA_SECURITY_PROTOCOL: Kafka client 和代理通信的协议, 如果要使用必须设置为 SASL ，无论是普通的还是使用SSL
* KAFKA_SASL_MECHANISM: 用于身份验证的的机制是 SASL 机制。
* KAFKA_SASL_USERNAME: SASL 的用户名
* KAFKA_SASL_PASSWORD: SASL 的密码

# Prometheus 配置

Prometheus 的基础配置是老朋友了，不需要特别说明，需要说明的是我们需要打开远程写功能，并且配置 `prometheus-kafka-adapter` 的地址和端口，像下边这样。
```
#远程写到 kafka adapter
remote_write:
  - url: "http://10.129.49.251:10410/receive"

scrape_configs:
  - job_name: 'promtsdb'
    static_configs:
      - targets:
      - 127.0.0.1:9090
```

配置好以后重新加载 Prometheus 的配置文件，然后去 Kafka 的 Topic 里查询数据。可以看到 Kafka 里的每条数据都是大约下边这种格式。

```
{
  "timestamp": "1970-01-01T00:00:00Z",
  "value": "9876543210",
  "name": "up",

  "labels": {
    "__name__": "up",
    "label1": "value1",
    "label2": "value2"
  }
}
```


# prometheus-kafka-adapter 的使用

上边的配置只是的实现了 Prometheus 将数据发送到了 Kafka 的目的，并且是一对一的关系。生产环境中的需求是多种多样的，我进行了如下尝试，并且获得了成功。

## 多个 Prometheus 实例向一个 adapter 推送数据

这个我做过测试，在每个 Prometheus 中配置同一个 `prometheus-kafka-adapter` 的地址和端口就可以实现，并且没有其他问题。

## 多个 adapter 向一个 Kafka Topic 推送数据

这个我也做过测试，在每个 `prometheus-kafka-adapter` 启动的时候都指定同一个 Kafka 的 Topic 就可以。Kafka 会正常接收数据，没有其他问题。

## 一个 adapter 向多个 Kafka Topic 推送数据

这个应该是无法实现的，adapter 启动的时候只能 指定一个 Kafka 的 Topic 。如果有一个 Prometheus 的数据想要推送到多个 Kafka 的 Topic ，应该是启动多个 adapter ，每个 adapter 配置对应点 Kafka 的 Topic ，然后在 Prometheus 的远程写配置中配置多个 adapter 的地址。

## 一个 Prometheus 想多个 adapter 推送数据

这种场景应该是启动多个 adapter ，每个 adapter 配置对应点 Kafka 的 Topic ，然后在 Prometheus 的远程写配置中配置多个 adapter 的地址。

## 一个 Prometheus 的部分 Job 向 adapter 推送数据

这个应该是无法实现的。Prometheus 的远程写功能是基于 Prometheus 实例全局来生效的，并不是基于 Prometheus 的 Job 来生效，所以如果一定要实现这种基于 Job 的推送，那么可以对 Prometheus 进行拆分，将需要推送的 Job 集中到一个 Prometheus 实例上，然后配置向 adapter 推送。这种情况需要构建 Prometheus 多实例集群，推荐基于 Thanos 来构建。

